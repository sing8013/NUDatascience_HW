{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize browser\n",
    "def init_browser():\n",
    "# @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape NASA Mars News\n",
    "def scrape_NASA():\n",
    "    browser=init_browser()\n",
    "    \n",
    "    #visit the NASA Mars News Site](https://mars.nasa.gov/news/\n",
    "    url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(url)\n",
    "    \n",
    "    #scrape page into soup\n",
    "    html = browser.html\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "    \n",
    "    #collect the latest News Title and Paragraph Text\n",
    "    latest_news = soup.find(\"div\", class_=\"list_text\")\n",
    "    #print(latest_news)\n",
    "    #news title\n",
    "    news_title=latest_news.find(\"div\",class_=\"content_title\").text\n",
    "    #print(news_title)\n",
    "    #paragraph text\n",
    "    news_p=latest_news.find(\"div\",class_=\"article_teaser_body\").text\n",
    "    \n",
    "    #store in dictionary\n",
    "    latest_news={\n",
    "        'title':news_title,\n",
    "        'paragraph':news_p\n",
    "    }\n",
    "    \n",
    "    return latest_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape JPL Mars Space Images\n",
    "def scrape_JPL():\n",
    "    browser = init_browser()\n",
    "    \n",
    "    #Visit the url for JPL Featured Space Image \n",
    "    #(https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars)\n",
    "    url=\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(url)\n",
    "    \n",
    "    #scrape page into soup\n",
    "    html=browser.html\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "    \n",
    "    #find and collect the featured image\n",
    "    featured_image = soup.find(\"section\",class_=\"centered_text clearfix main_feature primary_media_feature single\")\\\n",
    "                     .find(\"article\").find(\"a\")['data-fancybox-href']\n",
    "    \n",
    "    featured_image_url = 'https://www.jpl.nasa.gov'+ featured_image\n",
    "    \n",
    "    return featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape Mars Weather\n",
    "def scrape_mars_weather():\n",
    "    browser = init_browser()\n",
    "    #Visit the Mars Weather twitter account [here]\n",
    "    #(https://twitter.com/marswxreport?lang=en) \n",
    "    url = 'https://twitter.com/marswxreport?lang=en'\n",
    "    browser.visit(url)\n",
    "    \n",
    "    #scrape page into soup\n",
    "    html=browser.html\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "    \n",
    "    #scrape the latest Mars weather tweet from the page\n",
    "    mars_weather=soup.find(\"div\",class_=\"ProfileTimeline\")\\\n",
    "          .find(\"div\",class_=\"content\").find(\"p\").text\n",
    "    \n",
    "    return mars_weather\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape Mars Facts\n",
    "def scrape_mars_facts():\n",
    "    browser=init_browser()\n",
    "    \n",
    "    #Visit the Mars Facts webpage \n",
    "    #(http://space-facts.com/mars/) \n",
    "    url = 'http://space-facts.com/mars/'\n",
    "    browser.visit(url)\n",
    "    \n",
    "    #scrape page into soup\n",
    "    html=browser.html\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "    \n",
    "    #scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "    # use pandas to read the table\n",
    "    #table=pd.read_html(soup.find(\"table\",class_=\"tablepress tablepress-id-mars\"))\n",
    "    table=pd.read_html(soup)\n",
    "    df =pd.DataFrame(data=table)\n",
    "    df=table\n",
    "    #Use Pandas to convert the data to a HTML table string\n",
    "    mars_facts=df\n",
    "    \n",
    "    return mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-0deea8d06652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscrape_mars_facts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-e2c085112bae>\u001b[0m in \u001b[0;36mscrape_mars_facts\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# use pandas to read the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#table=pd.read_html(soup.find(\"table\",class_=\"tablepress tablepress-id-mars\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, tupleize_cols, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[1;32m    985\u001b[0m                   \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m                   \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m                   displayed_only=displayed_only)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;31m# this version of raise is a syntax error in Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "x=scrape_mars_facts()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One month since increasing their commanding frequency, engineers have yet to hear from NASA's Opportunity rover.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln['paragraph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
